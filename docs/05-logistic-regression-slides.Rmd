---
title: "Logistic Regression"
author: "Misk Academy"
date: "2020-6-22"
output:
  xaringan::moon_reader:
    css: ["custom.css"]
    self_contained: false
    lib_dir: libs
    chakra: libs/remark-latest.min.js
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    seal: false 
---

```{r setup, include=FALSE, cache=FALSE}
# Set global R options
options(htmltools.dir.version = FALSE, servr.daemon = TRUE)
# Set global knitr chunk options
knitr::opts_chunk$set(
  fig.align = "center", 
  cache = TRUE,
  error = FALSE,
  message = FALSE, 
  warning = FALSE, 
  collapse = TRUE 
)
library(tidyverse)
# set ggplot to black and white theme
library(ggplot2)
theme_set(theme_bw())
```

class: center, middle, inverse

.font300.white[Logistic Regression]

---
# Prerequisites

.pull-left[

```{r 08-pkgs, message=FALSE}
# Helper packages
library(dplyr)     # for data wrangling
library(ggplot2)   # for awesome plotting
library(rsample)   # for data splitting
# Modeling packages
library(caret)     # for logistic regression modeling
# Model interpretability packages
library(vip)       # variable importance
```

]

.pull-right[

```{r logit-data-import}
df <- attrition %>% mutate_if(is.ordered, factor, ordered = FALSE)
# Create training (70%) and test (30%) sets for the 
# rsample::attrition data.
set.seed(123)  # for reproducibility
churn_split <- initial_split(df, prop = .7, strata = "Attrition")
churn_train <- training(churn_split)
churn_test  <- testing(churn_split)
```

]

---
# Why logistic regression

.pull-left[

- Linear regression lacks the ability to adquately capture appropriate estimates of the response variable near the 0/1 (no/yes) boundaries
- Probability estimates tend to not be sensible (below 0% or above 100%)
- These inconsistencies only increase as our data become more imbalanced and the number of outliers increase

]

.pull-right[

```{r whylogit, echo=FALSE, fig.height=6}
ISLR::Default %>%
  mutate(prob = ifelse(default == "Yes", 1, 0)) %>%
  ggplot(aes(balance, prob)) +
  geom_point(alpha = .15) +
  geom_smooth(method = "lm") +
  ggtitle("Linear regression model fit") +
  xlab("Balance") +
  ylab("Probability of Default")

```
]

---
# Why logistic regression

.pull-left[

- Linear regression lacks the ability to adquately capture appropriate estimates of the response variable near the 0/1 (no/yes) boundaries
- Probability estimates tend to not be sensible (below 0% or above 100%)
- These inconsistencies only increase as our data become more imbalanced and the number of outliers increase
- .bold[The logistic function produces the S-shaped probability curve that better reflects reality]

\begin{equation}
  p\left(X\right) = \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1X}}
\end{equation}

]

.pull-right[

```{r whylogit2, echo=FALSE, fig.height=6}
ISLR::Default %>%
  mutate(prob = ifelse(default == "Yes", 1, 0)) %>%
  ggplot(aes(balance, prob)) +
  geom_point(alpha = .15) +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  ggtitle("Logistic regression model fit") +
  xlab("Balance") +
  ylab("Probability of Default")
```
]

---
# Simple logistic regression

.pull-left[

The $\beta_i$ parameters represent the coefficients as in linear regression and $p\left(X\right)$ may be interpreted as the probability that the positive class (default in the above example) is present.  The minimum for $p\left(x\right)$ is obtained at $\lim_{a \rightarrow -\infty} \left[ \frac{e^a}{1+e^a} \right] = 0$, and the maximum for $p\left(x\right)$ is obtained at $\lim_{a \rightarrow \infty} \left[ \frac{e^a}{1+e^a} \right] = 1$ which restricts the output probabilities to 0-1.

\begin{equation}
  g\left(X\right) = \ln \left[ \frac{p\left(X\right)}{1 - p\left(X\right)} \right] = \beta_0 + \beta_1 X
\end{equation}

]

.pull-right[

```{r glm-model1}
model1 <- glm(
 Attrition ~ MonthlyIncome, #<<
 family = "binomial", 
 data = churn_train
 )
```

```{r glm-sigmoid, echo=FALSE, fig.height=5}
churn_train2 <- churn_train %>% mutate(prob = ifelse(Attrition == "Yes", 1, 0))
churn_train2 <- broom::augment(model1, churn_train2) %>% mutate(.fitted = exp(.fitted))
ggplot(churn_train2, aes(MonthlyIncome, prob)) +
  geom_point(alpha = 0.15) +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  ggtitle("Predicted probability of attrition as income increases") +
  xlab("Monthly Income") +
  ylab("Probability of Attrition")
```

]

---
# Simple logistic regression

.pull-left[

The $\beta_i$ parameters represent the coefficients as in linear regression and $p\left(X\right)$ may be interpreted as the probability that the positive class (default in the above example) is present.  The minimum for $p\left(x\right)$ is obtained at $\lim_{a \rightarrow -\infty} \left[ \frac{e^a}{1+e^a} \right] = 0$, and the maximum for $p\left(x\right)$ is obtained at $\lim_{a \rightarrow \infty} \left[ \frac{e^a}{1+e^a} \right] = 1$ which restricts the output probabilities to 0-1.

\begin{equation}
  g\left(X\right) = \ln \left[ \frac{p\left(X\right)}{1 - p\left(X\right)} \right] = \beta_0 + \beta_1 X
\end{equation}

]

.pull-right[

```{r glm-model2}
model2 <- glm(
 Attrition ~ OverTime, #<<
 family = "binomial", 
 data = churn_train
 )
```

```{r glm-model2-sigmoid, echo=FALSE, fig.height=5}
churn_train2 <- churn_train %>% mutate(prob = ifelse(Attrition == "Yes", 1, 0))
churn_train2 <- broom::augment(model2, churn_train2) %>% mutate(.fitted = exp(.fitted))
ggplot(churn_train2, aes(OverTime, .fitted, color = OverTime)) +
  geom_boxplot(show.legend = FALSE) +
  geom_rug(sides = "b", position = "jitter", alpha = 0.2, show.legend = FALSE) +
  ggtitle("Predicted probability of attrition when working overtime") +
  xlab("Over Time") +
  scale_y_continuous("Probability of Attrition", limits = c(0, 1))
```

]

---
# Interpreting coefficients

- Coefficient estimates from logistic regression characterize the relationship between the predictor and response variable on a log-odds (i.e., logit) scale.
- Using the logit transformation results in an intuitive interpretation for the magnitude of $\beta_1$: the odds (e.g., of attrition) increase multiplicatively by exp( $\beta_1$) for every one-unit increase in X.

.pull-left[

```{r}
tidy(model1)
```

```{r}
exp(coef(model1))
```

]

.pull-right[

```{r}
tidy(model2)
```

```{r}
exp(coef(model2))
```

]

---
# Multiple logistic regression

We can also extend our model as seen in Equation 1 so that we can predict a binary response using multiple predictors:

\begin{equation}
p\left(X\right) = \frac{e^{\beta_0 + \beta_1 X + \cdots + \beta_p X_p }}{1 + e^{\beta_0 + \beta_1 X + \cdots + \beta_p X_p}} 
\end{equation}

.pull-left[

```{r glm-model3}
model3 <- glm(
  Attrition ~ MonthlyIncome + OverTime,
  family = "binomial", 
  data = churn_train
  )

tidy(model3)
```

]

.pull-right[

```{r glm-sigmoid2, echo=FALSE, fig.height=4.75}
churn_train3 <- churn_train %>% mutate(prob = ifelse(Attrition == "Yes", 1, 0))
churn_train3 <- broom::augment(model3, churn_train3) %>% mutate(.fitted = exp(.fitted))
ggplot(churn_train3, aes(MonthlyIncome, prob, color = OverTime)) +
  geom_point(alpha = .15) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) +
  ggtitle("Predicted probabilities for model3") +
  xlab("Monthly Income") +
  ylab("Probability of Attrition")
```

]

---
# Comparing model accuracy

.scrollable90[
.pull-left[

* three 10-fold cross validated logistic regression models
* both `cv_model1` and `cv_model2` had an average accuracy of 83.88%
* `cv_model3` which used all predictor variables in our data achieved an average accuracy rate of 87.58%

]

.pull-right[

```{r mult-models-logistic}
set.seed(123)
cv_model1 <- train(
  Attrition ~ MonthlyIncome, 
  data = churn_train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10)
)
set.seed(123)
cv_model2 <- train(
  Attrition ~ MonthlyIncome + OverTime, 
  data = churn_train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10)
)
set.seed(123)
cv_model3 <- train(
  Attrition ~ ., 
  data = churn_train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10)
)
# extract out of sample performance measures
summary(
  resamples(
    list(
      model1 = cv_model1, 
      model2 = cv_model2, 
      model3 = cv_model3
    )
  )
)$statistics$Accuracy
```

]
]

---
# Model performance

.scrollable90[
.pull-left[

* We can get a better understanding of our modelâ€™s performance by assessing the confusion matrix.
* .bold[Pro tip]: By default the `predict()` function predicts the response class for a caret model; however, you can change the `type` argument to predict the probabilities (see `?caret::predict.train`).

<br>

.center.bold[`No Information Rate: 0.8388`]
]

.pull-right[

```{r glm-confusion-matrix}
# predict class
pred_class <- predict(cv_model3, churn_train)
# create confusion matrix
confusionMatrix(
  data = relevel(pred_class, ref = "Yes"), 
  reference = relevel(churn_train$Attrition, ref = "Yes")
)
```

]
]

---
# Model performance

.scrollable90[
.pull-left[

* Our goal is to maximize our accuracy rate over and above this no information baseline while also trying to balance sensitivity and specificity.

* ROC curve helps to illustrate this "lift"

]

.pull-right[

```{r logistic-regression-roc}
library(ROCR)
# Compute predicted probabilities
m1_prob <- predict(cv_model1, churn_train, type = "prob")$Yes
m3_prob <- predict(cv_model3, churn_train, type = "prob")$Yes
# Compute AUC metrics for cv_model1 and cv_model3
perf1 <- prediction(m1_prob, churn_train$Attrition) %>%
  performance(measure = "tpr", x.measure = "fpr")
perf2 <- prediction(m3_prob, churn_train$Attrition) %>%
  performance(measure = "tpr", x.measure = "fpr")
# Plot ROC curves for cv_model1 and cv_model3
plot(perf1, col = "black", lty = 2)
plot(perf2, add = TRUE, col = "blue")
legend(0.8, 0.2, legend = c("cv_model1", "cv_model3"),
       col = c("black", "blue"), lty = 2:1, cex = 0.6)
```

]]

---
# Feature interpretation

.pull-left[

```{r glm-vip, fig.cap="Top 20 most important variables for the PLS model."}
vip(cv_model3, num_features = 20)
```

]

---
# Feature interpretation

.scrollable90[

```{r glm-pdp, fig.height=8, fig.width=9}
pred.fun <- function(object, newdata) {
  Yes <- mean(predict(object, newdata, type = "prob")$Yes)
  as.data.frame(Yes)
}

p1 <- pdp::partial(cv_model3, pred.var = "OverTime", pred.fun = pred.fun) %>% 
  ggplot(aes(OverTime, yhat)) + geom_point() + ylim(c(0, 1))

p2 <- pdp::partial(cv_model3, pred.var = "JobSatisfaction", pred.fun = pred.fun) %>% 
  ggplot(aes(JobSatisfaction, yhat)) + geom_point() + ylim(c(0, 1))

p3 <- pdp::partial(cv_model3, pred.var = "NumCompaniesWorked", pred.fun = pred.fun, gr = 10) %>% 
  ggplot(aes(NumCompaniesWorked, yhat)) + geom_point() + scale_x_continuous(breaks = 0:9) + ylim(c(0, 1))
  
p4 <- pdp::partial(cv_model3, pred.var = "EnvironmentSatisfaction", pred.fun = pred.fun) %>% 
  ggplot(aes(EnvironmentSatisfaction, yhat)) + geom_point() + ylim(c(0, 1))

grid.arrange(p1, p2, p3, p4, nrow = 2)
```

]

---
class: clear, center, middle

background-image: url(images/any-questions.jpg)
background-position: center
background-size: cover

---
# Back home

<br><br><br><br>
[.center[`r anicon::faa("home", size = 10, animate = FALSE)`]](https://github.com/misk-data-science/misk-homl)

.center[https://github.com/misk-data-science/misk-homl]
