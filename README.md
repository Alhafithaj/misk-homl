Hands-on machine learning for predictive analytics with R &amp; Python
================

### Misk Academy

-----

:spiral_calendar: September XX-XX, 2020  
:alarm_clock:     09:00 - 17:00  
:hotel:           TBD  
:writing_hand:    TBD

-----

## Overview

Students will learn many of the most common machine learning methods to include:

-	A proper modeling process 
-	Feature engineering
-	Linear and logistic regression 
-	Regularized models 
-	K-nearest neighbors 
-	Random forests 
-	Gradient boosting machines 
-	Stacking / super learners 
-	And more!

This module will teach students how to build and tune these various models with R and Python packages that have been tested and approved due to their ability to scale well (i.e. Scikit-Learn, xgboost, h2o). However, the motivation in almost every case is to describe the techniques in a way that helps develop intuition for its strengths and weaknesses. 

## Learning Objectives

TBD

## Prework

This module makes a few assumptions of your established knowledge regarding your programming skills and exposure to basic statistical concepts. Below are my assumptions and some resources to read through to make sure you are properly prepared.

| Assumptions                       | Resource      
| --------------------------------- | ------------- |
| You should be familiar with...    | [link](https://github.com/misk-data-science/misk-homl) | 
| You should be familiar with...    | [link](https://github.com/misk-data-science/misk-homl) | 
| You should be familiar with...    | [link](https://github.com/misk-data-science/misk-homl) | 
| You should be familiar with...    | [link](https://github.com/misk-data-science/misk-homl) | 


## Schedule

More info TBD.

| Session       | Description                          | Reading(s)    | Slides        | Source code             
| :-----------: | :----------------------------------- | :-----------: | :-----------: | :-----------: |
| 1             | Introduction to machine learning     | [Notebook](https://misk-data-science.github.io/misk-homl/docs/01-introduction.nb.html)  | TBD  | TBD   |
| 2             | The modeling process                 | [Notebook](https://misk-data-science.github.io/misk-homl/docs/02-modeling-process.nb.html)  | TBD  | TBD   |
| 3             | Feature and target engineering       | [Notebook](https://misk-data-science.github.io/misk-homl/docs/03-engineering.nb.html)  | TBD  | TBD   |
| 4             | Linear & logistic regression         | [Notebook](https://misk-data-science.github.io/misk-homl/docs/04-linear-regression.nb.html)  | TBD  | TBD   |
| 5             | Logistic regression                  | [Notebook](https://misk-data-science.github.io/misk-homl/docs/05-logistic-regression.nb.html)  | TBD  | TBD   |
| 6             | Regularized regression               | [Notebook]()  | TBD  | TBD   |
| 7             | Multivariate adaptive regression splines | [Notebook]()  | TBD  | TBD   |
| 8             | K-nearest neighbors                  | [Notebook]()  | TBD  | TBD   |
| 9             | Decision trees and bagging           | [Notebook]()  | TBD  | TBD   |
| 10            | Random forests                       | [Notebook]()  | TBD  | TBD   |
| 11            | Gradient boosting                    | [Notebook]()  | TBD  | TBD   |
| 12            | Stacked models & AutoML              | [Notebook]()  | TBD  | TBD   |
| 13            | Case study.                          | [Notebook]()  | TBD  | TBD   |


## Extras

TBD
